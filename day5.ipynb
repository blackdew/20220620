{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pix2pix GAN"
      ],
      "metadata": {
        "id": "OGggfWdRfd8Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5xv1JmXfcN1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비"
      ],
      "metadata": {
        "id": "YB7nc3GoflWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz -O ./facades.tar.gz\n",
        "!tar -xvzf facades.tar.gz >> log.txt"
      ],
      "metadata": {
        "id": "M_FF8AkBfk9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/facades'\n",
        "image = tf.io.read_file(f'{path}/train/100.jpg')\n",
        "image = tf.io.decode_jpeg(image)\n",
        "print(image.shape)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KzkNMxeJfqOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/facades'\n",
        "image = tf.io.read_file(f'{path}/train/100.jpg')\n",
        "image = tf.io.decode_jpeg(image)\n",
        "\n",
        "w = tf.shape(image)[1] // 2\n",
        "input, real = image[:, w:, :], image[:, :w, :]\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(input)\n",
        "plt.subplot(122)\n",
        "plt.imshow(real)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CeQP-0DJfr9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_train(file):\n",
        "    input, real = load(file)\n",
        "    input, real = random_jitter(input, real)\n",
        "    return input, real\n",
        "\n",
        "def preprocess_test(file):\n",
        "    input, real = load(file)\n",
        "    return input, real\n",
        "\n",
        "def load(path):\n",
        "    image = tf.io.decode_jpeg(tf.io.read_file(path))\n",
        "    image = (tf.cast(image, tf.float32) - 127.5) / 127.5\n",
        "    w = tf.shape(image)[1] // 2\n",
        "    return image[:, w:, :], image[:, :w, :]\n",
        "\n",
        "def random_jitter(input, real):\n",
        "    input = tf.image.resize(input, [286, 286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    real = tf.image.resize(real, [286, 286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "    stacked = tf.stack([input, real], axis=0)\n",
        "    croped = tf.image.random_crop(stacked, size=[2, 256, 256, 3])\n",
        "\n",
        "    input, real = croped[0], croped[1]\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input = tf.image.flip_left_right(input)\n",
        "        real = tf.image.flip_left_right(real)\n",
        "\n",
        "    return input, real"
      ],
      "metadata": {
        "id": "KzMxZfsSft6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/facades'\n",
        "train = tf.data.Dataset.list_files(f'{path}/train/*.jpg')\n",
        "train = train.map(preprocess_train).shuffle(400).batch(4)\n",
        "test = tf.data.Dataset.list_files(f\"{path}/test/*.jpg\")\n",
        "test = test.map(preprocess_test).batch(5)"
      ],
      "metadata": {
        "id": "fAYtqHxJfv2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "input, real = next(iter(train))\n",
        "print(input.shape, real.shape)\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(input[0] * 0.5 + 0.5)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(real[0] * 0.5 + 0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "avTSYirafx0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 생성"
      ],
      "metadata": {
        "id": "kLv5cm2tf66u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample(x, filters):\n",
        "    h = tf.keras.layers.Conv2D(filters, 4, 2, padding='same')(x)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "    return h\n",
        "\n",
        "def upsample(x, filters, dropout=False):\n",
        "    h = tf.keras.layers.Conv2DTranspose(filters, 4, 2, padding='same')(x)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    if dropout:\n",
        "        h = tf.keras.layers.Dropout(0.5)(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "    return h"
      ],
      "metadata": {
        "id": "9VIytUwff425"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator():\n",
        "    x = tf.keras.layers.Input(shape=[256, 256, 3])\n",
        "\n",
        "    h1 = tf.keras.layers.Conv2D(64, 4, 2, 'same', activation=\"relu\")(x)\n",
        "    h2 = downsample(h1, 128)\n",
        "    h3 = downsample(h2, 256)\n",
        "    h4 = downsample(h3, 512)\n",
        "    h5 = downsample(h4, 512)\n",
        "    h6 = downsample(h5, 512)\n",
        "    h7 = downsample(h6, 512)\n",
        "    h8 = downsample(h7, 512) # (1, 1, 512)\n",
        "\n",
        "    h = upsample(h8, 512, dropout=True)\n",
        "    h = tf.keras.layers.Concatenate()([h, h7])\n",
        "    h = upsample(h, 512, dropout=True)\n",
        "    h = tf.keras.layers.Concatenate()([h, h6])\n",
        "    h = upsample(h, 512, dropout=True)\n",
        "    h = tf.keras.layers.Concatenate()([h, h5])\n",
        "    h = upsample(h, 512)\n",
        "    h = tf.keras.layers.Concatenate()([h, h4])\n",
        "    h = upsample(h, 256)\n",
        "    h = tf.keras.layers.Concatenate()([h, h3])\n",
        "    h = upsample(h, 128)\n",
        "    h = tf.keras.layers.Concatenate()([h, h2])\n",
        "    h = upsample(h, 64)\n",
        "    h = tf.keras.layers.Concatenate()([h, h1])\n",
        "    \n",
        "    y = tf.keras.layers.Conv2DTranspose(3, 4, 2, padding='same', activation='tanh')(h)\n",
        "\n",
        "    return tf.keras.Model(x, y)"
      ],
      "metadata": {
        "id": "0HWASnVRf88X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator():\n",
        "    x1 = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "    x2 = tf.keras.layers.Input(shape=[256, 256, 3], name='real_image')\n",
        "    x = tf.keras.layers.concatenate([x1, x2])  # (256, 256, 6)\n",
        "\n",
        "    h = tf.keras.layers.Conv2D(64, 4, 2, padding='same', activation=\"relu\")(x)\n",
        "    h = downsample(h, 128)\n",
        "    h = downsample(h, 256)\n",
        "    h = tf.keras.layers.Conv2D(512, 4, padding=\"same\")(h)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation(\"relu\")(h)\n",
        "    y = tf.keras.layers.Conv2D(1, 4, padding=\"same\")(h)  # (30, 30, 1)\n",
        "\n",
        "    return tf.keras.Model([x1, x2], y)"
      ],
      "metadata": {
        "id": "Efs5NyoxgAFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Pix2pix(tf.keras.Model):\n",
        "    def __init__(self, generator, discriminator):\n",
        "        super(Pix2pix, self).__init__()\n",
        "        self.compile()\n",
        "\n",
        "        self.generator = generator \n",
        "        self.discriminator = discriminator\n",
        "\n",
        "        self.g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "        self.d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "        self.crossentropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "        self.d_loss = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def discriminator_loss(self, y_real, y_generate):\n",
        "        real_loss = self.crossentropy(tf.ones_like(y_real), y_real)\n",
        "        generate_loss = self.crossentropy(tf.zeros_like(y_generate), y_generate)\n",
        "        return real_loss + generate_loss\n",
        "            \n",
        "    def generator_loss(self, y_generate, generate, real):\n",
        "        g_loss = self.crossentropy(tf.ones_like(y_generate), y_generate)\n",
        "        l1_loss = tf.reduce_mean(tf.abs(real - generate))\n",
        "        return g_loss + (100 * l1_loss)\n",
        "\n",
        "    def update_metrics(self, g_loss, d_loss):\n",
        "        self.g_loss.update_state(g_loss)\n",
        "        self.d_loss.update_state(d_loss)\n",
        "\n",
        "    def train_step(self, dataset):\n",
        "        input, real = dataset\n",
        "\n",
        "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
        "            generate = self.generator(input, training=True)\n",
        "\n",
        "            y_real = self.discriminator([input, real], training=True)\n",
        "            y_generate = self.discriminator([input, generate], training=True)\n",
        "\n",
        "            g_loss = self.generator_loss(y_generate, generate, real)\n",
        "            d_loss = self.discriminator_loss(y_real, y_generate)\n",
        "\n",
        "        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
        "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n",
        "\n",
        "        self.update_metrics(g_loss, d_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss.result(),\n",
        "            \"g_loss\": self.g_loss.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "8mTtTgEugB4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 훈련"
      ],
      "metadata": {
        "id": "-UbGVXZcgJJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "generator = make_generator()\n",
        "discriminator = make_discriminator()\n",
        "gan = Pix2pix(generator, discriminator) "
      ],
      "metadata": {
        "id": "vGD0-_0CgDjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "class Monitor(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        display.clear_output(wait=True)\n",
        "        input, real = next(iter(test))\n",
        "        generated = self.model.generator(input)\n",
        "\n",
        "        for i in range(3):\n",
        "            plt.figure(figsize=(10, 10))\n",
        "\n",
        "            plt.subplot(131)\n",
        "            plt.imshow(input[i] * 0.5 + 0.5)\n",
        "\n",
        "            plt.subplot(132)\n",
        "            plt.imshow(real[i] * 0.5 + 0.5)\n",
        "\n",
        "            plt.subplot(133)\n",
        "            plt.imshow(generated[i] * 0.5 + 0.5)\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "gan.fit(train, epochs=50, callbacks=[Monitor()])"
      ],
      "metadata": {
        "id": "QaKXeFQZgLKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과 확인"
      ],
      "metadata": {
        "id": "c4UP3EPLgQ7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input, real in test.take(5):\n",
        "    print(input.shape, real.shape)\n",
        "    \n",
        "    pred = generator.predict(input)\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    display_list = [input[0], real[0], pred[0]]\n",
        "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CMTMm319gMe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cycle Gan"
      ],
      "metadata": {
        "id": "WEy-auLogYU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비 - unpaired\n",
        "- Pix2pix의 preprocess 함수를 그대로 이용. "
      ],
      "metadata": {
        "id": "BquDBEqTgbPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/facades'\n",
        "files_train = tf.data.Dataset.list_files(f'{path}/train/*.jpg')\n",
        "train = files_train.map(preprocess_train).shuffle(400).batch(400)\n",
        "files_test = tf.data.Dataset.list_files(f\"{path}/test/*.jpg\")\n",
        "test = files_test.map(preprocess_test).batch(5)\n",
        "\n",
        "# unpairing\n",
        "trainA, trainB = next(iter(train))\n",
        "trainB = tf.random.shuffle(trainB)\n",
        "train = tf.data.Dataset.from_tensor_slices((trainA.numpy(), trainB.numpy()))\n",
        "train = train.shuffle(400).batch(4)"
      ],
      "metadata": {
        "id": "Sppa7wqggV3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "input, real = next(iter(train))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(input[0] * 0.5 + 0.5)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(real[0] * 0.5 + 0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3OpHI-rYgcpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 생성 \n",
        "- generator는 Pix2pix에서 사용한 make_generator 함수를 그대로 이용한다. "
      ],
      "metadata": {
        "id": "wFOukLzbgl3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator():\n",
        "    x = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "\n",
        "    h = tf.keras.layers.Conv2D(64, 4, 2, padding='same', activation=\"relu\")(x)\n",
        "    h = downsample(h, 128)\n",
        "    h = downsample(h, 256)\n",
        "    h = tf.keras.layers.Conv2D(512, 4, padding=\"same\")(h)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation(\"relu\")(h)\n",
        "    y = tf.keras.layers.Conv2D(1, 4, padding=\"same\")(h)  # (30, 30, 1)\n",
        "\n",
        "    return tf.keras.Model(x, y)\n",
        "    "
      ],
      "metadata": {
        "id": "F7F7MWTck6ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGAN(tf.keras.Model):\n",
        "    def __init__(self, genAB, genBA, discA, discB):\n",
        "        super(CycleGAN, self).__init__()\n",
        "        self.compile()\n",
        "\n",
        "        # 생성기 \n",
        "        self.genAB = genAB\n",
        "        self.genBA = genBA\n",
        "        self.gAB_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "        self.gBA_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "        # 판별기\n",
        "        self.discA = discA \n",
        "        self.discB = discB \n",
        "        self.dA_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "        self.dB_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "        self.crossentropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def discriminator_loss(self, y_real, y_generate):\n",
        "        real_loss = self.crossentropy(tf.ones_like(y_real), y_real)\n",
        "        generate_loss = self.crossentropy(tf.zeros_like(y_generate), y_generate)\n",
        "        return (real_loss + generate_loss) * 0.5\n",
        "\n",
        "    def generator_loss(self, y_generate):\n",
        "        g_loss = self.crossentropy(tf.ones_like(y_generate), y_generate)\n",
        "        return g_loss\n",
        "\n",
        "    def cycle_loss(self, real, cycle):\n",
        "        return 10 * tf.reduce_mean(tf.abs(real - cycle))\n",
        "\n",
        "    def identity_loss(self, real, same):\n",
        "        return 10 * 0.5 * tf.reduce_mean(tf.abs(real - same))        \n",
        "        \n",
        "    def train_step(self, dataset):\n",
        "        realA, realB = dataset\n",
        "        \n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            generateB = self.genAB(realA, training=True)\n",
        "            cycleA = self.genBA(generateB, training=True)\n",
        "            generateA = self.genBA(realB, training=True)\n",
        "            cycleB = self.genAB(generateA, training=True)\n",
        "            sameA = self.genBA(realA, training=True)\n",
        "            sameB = self.genAB(realB, training=True)\n",
        "\n",
        "            y_realA = self.discA(realA, training=True)\n",
        "            y_realB = self.discB(realB, training=True)\n",
        "            y_generateA = self.discA(generateA, training=True)\n",
        "            y_generateB = self.discB(generateB, training=True)\n",
        "\n",
        "            # Total generator loss = adversarial loss + cycle loss\n",
        "            total_cycle_loss = self.cycle_loss(realA, cycleA) + self.cycle_loss(realB, cycleB)\n",
        "            gAB_loss = self.generator_loss(y_generateB) + total_cycle_loss + self.identity_loss(realB, sameB)\n",
        "            gBA_loss = self.generator_loss(y_generateA) + total_cycle_loss + self.identity_loss(realA, sameA)\n",
        "            dA_loss = self.discriminator_loss(y_realA, y_generateA)\n",
        "            dB_loss = self.discriminator_loss(y_realB, y_generateB)\n",
        "    \n",
        "        # Calculate the gradients for generator and discriminator\n",
        "        gAB_gradients = tape.gradient(gAB_loss, self.genAB.trainable_variables)\n",
        "        gBA_gradients = tape.gradient(gBA_loss, self.genBA.trainable_variables)\n",
        "        dA_gradients = tape.gradient(dA_loss, self.discA.trainable_variables)\n",
        "        dB_gradients = tape.gradient(dB_loss, self.discB.trainable_variables)\n",
        "\n",
        "        self.gAB_optimizer.apply_gradients(zip(gAB_gradients, self.genAB.trainable_variables))\n",
        "        self.gBA_optimizer.apply_gradients(zip(gBA_gradients, self.genBA.trainable_variables))\n",
        "        self.dA_optimizer.apply_gradients(zip(dA_gradients, self.discA.trainable_variables))\n",
        "        self.dB_optimizer.apply_gradients(zip(dB_gradients, self.discB.trainable_variables))\n",
        "        \n",
        "        self.d_loss_metric.update_state(dA_loss + dB_loss)\n",
        "        self.g_loss_metric.update_state(gAB_loss + gBA_loss)\n",
        "\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "U8FFkM7ygjco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "CNL-V1NnhBIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "genAB = make_generator()\n",
        "genBA = make_generator()\n",
        "discA = make_discriminator()\n",
        "discB = make_discriminator()\n",
        "gan = CycleGAN(genAB, genBA, discA, discB) "
      ],
      "metadata": {
        "id": "wAevYmyYgo3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "g_real = genAB(input)\n",
        "g_input = genBA(real)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(221)\n",
        "plt.imshow(input[0] * 0.5 + 0.5)\n",
        "plt.subplot(222)\n",
        "plt.imshow(g_real[0] * 0.5 * 8 + 0.5)\n",
        "plt.subplot(223)\n",
        "plt.imshow(real[0] * 0.5 + 0.5)\n",
        "plt.subplot(224)\n",
        "plt.imshow(g_input[0] * 0.5 * 8 + 0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s6ieyJDvhCfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "class Monitor(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        display.clear_output(wait=True)\n",
        "        testA, testB = next(iter(test))\n",
        "        generated = self.model.genAB(testA)\n",
        "\n",
        "        for i in range(3):\n",
        "            plt.subplot(131)\n",
        "            plt.imshow(testA[i] * 0.5 + 0.5)\n",
        "\n",
        "            plt.subplot(132)\n",
        "            plt.imshow(testB[i] * 0.5 + 0.5)\n",
        "\n",
        "            plt.subplot(133)\n",
        "            plt.imshow(generated[i] * 0.5 + 0.5)\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "gan.fit(train, epochs=20, callbacks=[Monitor()])"
      ],
      "metadata": {
        "id": "UhYa_veShDzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과 확인"
      ],
      "metadata": {
        "id": "y9jemQu-hILE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for testA, testB in test.take(5):\n",
        "    generated = genAB(testA)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    display_list = [testA[0], testB[0], generated[0]]\n",
        "    title = ['Input Image', 'Target Image', 'Predicted Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "70OY3M_MhGBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eMteVU_-hJXJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}